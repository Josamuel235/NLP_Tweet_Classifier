{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josep\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## run this if you get an error for missing imports\n",
    "! pip install gradio\n",
    "! pip install numpy\n",
    "! pip install pickle\n",
    "! pip install torch\n",
    "! pip install spacy\n",
    "! python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josep\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from LSTM_Architecture import NLP_LSTM\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "file = open('tok_to_work', 'rb')\n",
    "tok_convert = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('tok_track', 'rb')\n",
    "tok_track = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "model = NLP_LSTM(gpu, 150, 150, len(tok_convert), 4, 0.44, True)\n",
    "info = torch.load('latest_model.pt', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(info['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_processor:\n",
    "    def __init__(self, tokenized_df, conv, track):\n",
    "        self.word_idx = conv\n",
    "        self.tracker = track\n",
    "        self.most = 29\n",
    "        self.threshold = 4\n",
    "        normalized = tokenized_df['tweet'].apply(data_processor.sentence_normalizer, args=(self,))\n",
    "        normalized_df = tokenized_df.assign(tweet = normalized)\n",
    "        numerized = normalized_df['tweet'].apply(data_processor.numerizer, args=(self,))\n",
    "        self.text = normalized_df.assign(numerized_tweet = numerized)\n",
    "\n",
    "\n",
    "    def sentence_normalizer(sentence, self):\n",
    "        final_tok = []\n",
    "        count = 0 \n",
    "        for token in sentence:\n",
    "            final_tok.append(token)\n",
    "            count+=1\n",
    "            if count >= self.most:\n",
    "                break\n",
    "        if len(final_tok)<self.most:\n",
    "            final_tok.extend(['<PAD>']*(self.most-len(final_tok)))\n",
    "        return final_tok\n",
    "\n",
    "\n",
    "    def numerizer(x, self):\n",
    "        base = []\n",
    "        for token in x:\n",
    "            try:\n",
    "                if token.norm in self.tracker:\n",
    "                    if self.tracker[token.norm]>= self.threshold:\n",
    "                        base.append(self.word_idx[str(token)])\n",
    "                    else:\n",
    "                        base.append(self.word_idx['<UNK>'])\n",
    "                else:\n",
    "                    base.append(self.word_idx['<UNK>'])\n",
    "            except:\n",
    "                base.append(self.word_idx['<PAD>'])\n",
    "\n",
    "        return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(Text):\n",
    "        repl = {'@\\w*': ' ', '&amp;' : 'and','\\su\\s':' you ', '&#\\w*;': ' ', \n",
    "        '#':' ', '\\s2\\s': 'two', 'bihday':\"birthday\", \"ð[^ ]*\": ' ' ,\n",
    "        \"â[^ ]*\": ' ',\"(dont)|(don't)\": 'do not', \"(cant)|(can't)\": \"can not\",\n",
    "        \"(yous)|(you's)\": \"you is\", \"(yous)|(you's)\": \"you is\", \n",
    "        \"(youve)|(you've)\": \"you have\", \"(doesnt)|(doesn't)\": 'does not', \n",
    "        \"(wont)|(won't)\": 'will not', \"[0-9]+\\.*[0-9%]+\\w*\" : \"NUMBER\",'\\\\n\\.':' ' ,'\\\\n':' ',\n",
    "        \"\\.{2,}\": '.', \"!{2,}\":'!', \"\\?{2,}\":'?', 'ing[^a-z]':' ', 'ed[^a-z]': ' ', '_':\" \",\n",
    "        ' +': ' '}\n",
    "\n",
    "        text = pd.DataFrame({'tweet': [Text]})\n",
    "        cleaned = text['tweet'].str.lower()\n",
    "        cleaned = cleaned.replace(repl, regex=True)\n",
    "        text = text.assign(tweet = cleaned)\n",
    "        cleaned = text['tweet'].apply(lambda x: nlp(x.strip()))\n",
    "        text = text.assign(tweet = cleaned)\n",
    "        tok_convert\n",
    "        text = data_processor(text, tok_convert, tok_track)\n",
    "        text = text.text\n",
    "        text = torch.tensor(np.stack(text['numerized_tweet']))\n",
    "        text = torch.round(model.tester(text)).item()\n",
    "        if text == 1:\n",
    "                return 'This is Toxic'\n",
    "        else:\n",
    "                return 'This is not Toxic'\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josep\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "c:\\Users\\Josep\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "c:\\Users\\Josep\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "c:\\Users\\Josep\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    }
   ],
   "source": [
    "outputs = gr.outputs.Textbox()\n",
    "inputs = gr.inputs.Textbox()\n",
    "app = gr.Interface(fn=run, inputs=[inputs], outputs=outputs,description=\"This is a Sentiment Analysis Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitterscrape",
   "language": "python",
   "name": "twitterscrape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
